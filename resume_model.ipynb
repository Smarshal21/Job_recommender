{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GIQPrFTy94eU",
        "outputId": "f6c7f721-7c78-4b91-9552-165e1e7b97b1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "%pip install langchain\n",
        "from langchain import HuggingFaceHub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "eFiI6olC-yFL",
        "outputId": "4d4fd6d1-3f0d-49ec-cbf6-860b101ddf5c"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"jobs (1).csv\")\n",
        "df[\"result\"]=df[\"company_id\"]+df[\"job_name\"] +\tdf[\"taglist\"]\t+df[\"location\"]\t+df[\"three_reasons\"]\t+df[\"description\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7jqdk_79Jd4N"
      },
      "outputs": [],
      "source": [
        "df.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XEEGYBH-8igG"
      },
      "outputs": [],
      "source": [
        "!pip install faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vk5sceOkAsMN"
      },
      "outputs": [],
      "source": [
        "!pip install sentence-transformers\n",
        "from sentence_transformers import SentenceTransformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "blWBQ6YjI9Cl",
        "outputId": "4c4c4d28-f7fd-45b4-e1c4-8149c32317c2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import google.generativeai as genai\n",
        "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "model = SentenceTransformer(model_name)\n",
        "api_key = \"YOUR_GEN_AI_API_KEY\"\n",
        "genai.configure(api_key=api_key)\n",
        "genmodel = genai.GenerativeModel('gemini-pro')\n",
        "import faiss\n",
        "import numpy as np\n",
        "chunks_embeddings = []\n",
        "for i in range(len(df)):\n",
        "    if isinstance(df['result'][i], str):\n",
        "        # Process only if the element is a string\n",
        "        text = df[\"result\"][i]\n",
        "        embedding = model.encode(text)\n",
        "        chunks_embeddings.append((text, embedding))\n",
        "    else:\n",
        "        # Skip if the element is not a string\n",
        "        continue\n",
        "\n",
        "dimension = chunks_embeddings[0][1].shape[0]\n",
        "embeddings_array = np.array([emb for _, emb in chunks_embeddings]).astype('float32')\n",
        "faiss_index = faiss.IndexFlatL2(dimension)\n",
        "faiss_index.add(embeddings_array)\n",
        "import pickle\n",
        "with open(\"pickle_file\", 'wb') as f:\n",
        "    pickle.dump(faiss_index, f)\n",
        "\n",
        "def answer(text):\n",
        "  query_embedding = model.encode(text)\n",
        "  query_embedding = np.array([query_embedding]).astype('float32')\n",
        "  k = 10\n",
        "  D, I = faiss_index.search(query_embedding, k)\n",
        "  retrieved_list = [chunks_embeddings[i][0] for i in I[0]]\n",
        "  import re\n",
        "  texts=[]\n",
        "  for text in retrieved_list:\n",
        "   texts.append(text)\n",
        "  response = genmodel.generate_content(\"find the name of the company , job , description and location for each item in the list of individually {texts}\".format(texts=texts))\n",
        "\n",
        "  return response.text\n",
        "\n",
        "# Get user input\n",
        "text = input(\"Enter the details here: \")\n",
        "response = answer(text)\n",
        "print(response)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "crf8Sb9KKsL8"
      },
      "outputs": [],
      "source": [
        "with open(\"pickle_file\", 'rb') as f:\n",
        "    loaded_data = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "f_p9pxKRQBPo",
        "outputId": "50ca1242-dd4b-45d6-f9be-d8c60f5593e8"
      },
      "outputs": [],
      "source": [
        "def answer(text):\n",
        "  query_embedding = model.encode(text)\n",
        "  query_embedding = np.array([query_embedding]).astype('float32')\n",
        "  k = 10\n",
        "  D, I = loaded_data.search(query_embedding, k)\n",
        "  retrieved_list = [chunks_embeddings[i][0] for i in I[0]]\n",
        "  import re\n",
        "  texts=[]\n",
        "  for text in retrieved_list:\n",
        "   texts.append(text)\n",
        "  response = genmodel.generate_content(\"find the name of the company , job , description and location for all the 10 elements in the  {texts}\".format(texts=texts))\n",
        "  return response.text\n",
        "\n",
        "\n",
        "text = input(\"Enter the details here: \")\n",
        "response = answer(text)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YEkjjfRTXB5r"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
